{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9042abbb",
   "metadata": {},
   "source": [
    "## 0. Cuda Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3faab0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\ifanglab\\anaconda3\\envs\\rag\\lib\\site-packages (2.7.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\ifanglab\\anaconda3\\envs\\rag\\lib\\site-packages (0.22.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\ifanglab\\anaconda3\\envs\\rag\\lib\\site-packages (2.7.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\ifanglab\\anaconda3\\envs\\rag\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\ifanglab\\anaconda3\\envs\\rag\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\ifanglab\\anaconda3\\envs\\rag\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\ifanglab\\anaconda3\\envs\\rag\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ifanglab\\anaconda3\\envs\\rag\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ifanglab\\anaconda3\\envs\\rag\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ifanglab\\anaconda3\\envs\\rag\\lib\\site-packages (from torch) (78.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ifanglab\\anaconda3\\envs\\rag\\lib\\site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ifanglab\\anaconda3\\envs\\rag\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ifanglab\\anaconda3\\envs\\rag\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ifanglab\\anaconda3\\envs\\rag\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\ifanglab\\anaconda3\\envs\\rag\\lib\\site-packages (2.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0208f8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0+cu118\n",
      "True\n",
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "import numpy\n",
    "print(numpy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8214685",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e91851",
   "metadata": {},
   "source": [
    "### 1.1 Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67019860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/brandonstarxel/chunking_evaluation.git --quiet\n",
    "%pip install hf_xet --quiet\n",
    "%pip install bitsandbytes --quiet\n",
    "%pip install --upgrade transformers --quiet\n",
    "%pip install --upgrade chromadb --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfff2969",
   "metadata": {},
   "source": [
    "### 1.2 Import Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d01aee84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·²å°‡å°ˆæ¡ˆæ ¹ç›®éŒ„ 'd:\\ArtificialIntelligenceCustomerService\\code\\exp' å„ªå…ˆåŠ å…¥åˆ° Python æ¨¡çµ„æœå°‹è·¯å¾‘ã€‚\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# å–å¾—ç›®å‰ç­†è¨˜æœ¬æª”æ¡ˆçš„çµ•å°è·¯å¾‘\n",
    "notebook_path = os.path.abspath('chunking_exp.ipynb')\n",
    "\n",
    "# å–å¾—ç­†è¨˜æœ¬æ‰€åœ¨çš„ç›®éŒ„ï¼ˆå³å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼‰\n",
    "project_root = os.path.dirname(notebook_path)\n",
    "\n",
    "# å°‡å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼ˆåŒ…å«ä½ çš„æœ¬åœ° chunking_evaluation è³‡æ–™å¤¾ï¼‰\n",
    "# æ’å…¥åˆ° sys.path çš„æœ€å‰é¢ï¼Œç¢ºä¿å„ªå…ˆè¼‰å…¥æœ¬åœ°ç‰ˆæœ¬\n",
    "sys.path.insert(0, project_root)\n",
    "print(f\"å·²å°‡å°ˆæ¡ˆæ ¹ç›®éŒ„ '{project_root}' å„ªå…ˆåŠ å…¥åˆ° Python æ¨¡çµ„æœå°‹è·¯å¾‘ã€‚\")\n",
    "\n",
    "\n",
    "from chunking_evaluation.chunking import FixedTokenChunker, RecursiveTokenChunker\n",
    "from chunking_evaluation import GeneralEvaluation, SyntheticEvaluation\n",
    "from chunking_evaluation.utils import bge_m3_token_count, get_bge_m3_embedding_function\n",
    "from chunking_evaluation.evaluation_framework.general_evaluation_data.DatasetAnalyzer import DatasetAnalyzer\n",
    "import pandas as pd\n",
    "from IPython.display import display, clear_output\n",
    "import http.client\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dff1647",
   "metadata": {},
   "source": [
    "### 1.3 Setup Embedding Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e9f8e5",
   "metadata": {},
   "source": [
    "## 2. Create Chunkers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bad7fd",
   "metadata": {},
   "source": [
    "### 2.1 RecursiveTokenChunker & FixedTokenChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b0aa7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunkers = [\n",
    "    # chunk_size = 512\n",
    "    RecursiveTokenChunker(chunk_size=512, chunk_overlap=50, length_function=bge_m3_token_count),\n",
    "    FixedTokenChunker(chunk_size=512, chunk_overlap=50),\n",
    "\n",
    "    RecursiveTokenChunker(chunk_size=512, chunk_overlap=100, length_function=bge_m3_token_count),\n",
    "    FixedTokenChunker(chunk_size=512, chunk_overlap=100),\n",
    "\n",
    "    RecursiveTokenChunker(chunk_size=512, chunk_overlap=150, length_function=bge_m3_token_count),\n",
    "    FixedTokenChunker(chunk_size=512, chunk_overlap=150),\n",
    "\n",
    "    RecursiveTokenChunker(chunk_size=512, chunk_overlap=200, length_function=bge_m3_token_count),\n",
    "    FixedTokenChunker(chunk_size=512, chunk_overlap=200),\n",
    "    '''\n",
    "    # chunk_size = 1024\n",
    "    RecursiveTokenChunker(chunk_size=1024, chunk_overlap=50, length_function=bge_m3_token_count),\n",
    "    FixedTokenChunker(chunk_size=1024, chunk_overlap=50),\n",
    "\n",
    "    RecursiveTokenChunker(chunk_size=1024, chunk_overlap=100, length_function=bge_m3_token_count),\n",
    "    FixedTokenChunker(chunk_size=1024, chunk_overlap=100),\n",
    "\n",
    "    RecursiveTokenChunker(chunk_size=1024, chunk_overlap=150, length_function=bge_m3_token_count),\n",
    "    FixedTokenChunker(chunk_size=1024, chunk_overlap=150),\n",
    "\n",
    "    RecursiveTokenChunker(chunk_size=1024, chunk_overlap=200, length_function=bge_m3_token_count),\n",
    "    FixedTokenChunker(chunk_size=1024, chunk_overlap=200),\n",
    "\n",
    "    # chunk_size = 2048\n",
    "    RecursiveTokenChunker(chunk_size=2048, chunk_overlap=50, length_function=bge_m3_token_count),\n",
    "    FixedTokenChunker(chunk_size=2048, chunk_overlap=50),\n",
    "\n",
    "    RecursiveTokenChunker(chunk_size=2048, chunk_overlap=100, length_function=bge_m3_token_count),\n",
    "    FixedTokenChunker(chunk_size=2048, chunk_overlap=100),\n",
    "\n",
    "    RecursiveTokenChunker(chunk_size=2048, chunk_overlap=150, length_function=bge_m3_token_count),\n",
    "    FixedTokenChunker(chunk_size=2048, chunk_overlap=150),\n",
    "\n",
    "    RecursiveTokenChunker(chunk_size=2048, chunk_overlap=200, length_function=bge_m3_token_count),\n",
    "    FixedTokenChunker(chunk_size=2048, chunk_overlap=200),\n",
    "\n",
    "    # chunk_size = 4096\n",
    "    RecursiveTokenChunker(chunk_size=4096, chunk_overlap=50, length_function=bge_m3_token_count),\n",
    "    FixedTokenChunker(chunk_size=4096, chunk_overlap=50),\n",
    "\n",
    "    RecursiveTokenChunker(chunk_size=4096, chunk_overlap=100, length_function=bge_m3_token_count),\n",
    "    FixedTokenChunker(chunk_size=4096, chunk_overlap=100),\n",
    "\n",
    "    RecursiveTokenChunker(chunk_size=4096, chunk_overlap=150, length_function=bge_m3_token_count),\n",
    "    FixedTokenChunker(chunk_size=4096, chunk_overlap=150),\n",
    "\n",
    "    RecursiveTokenChunker(chunk_size=4096, chunk_overlap=200, length_function=bge_m3_token_count),\n",
    "    FixedTokenChunker(chunk_size=4096, chunk_overlap=200),\n",
    "    '''\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df4b187",
   "metadata": {},
   "source": [
    "## 3. Prepare Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02754655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è·³éä¸‹è¼‰ç¯„ä¾‹æ–‡æœ¬ã€‚\n"
     ]
    }
   ],
   "source": [
    "def download_text(book_id, file_name, directory):\n",
    "    conn = http.client.HTTPSConnection(\"www.gutenberg.org\")\n",
    "    url = f\"/files/{book_id}/{book_id}-0.txt\"\n",
    "\n",
    "    conn.request(\"GET\", url)\n",
    "    response = conn.getresponse()\n",
    "\n",
    "    if response.status == 200:\n",
    "        text = response.read().decode('utf-8')\n",
    "\n",
    "        # Create directory if it does not exist\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "        # Save the text to the specified file within the directory\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text)\n",
    "        print(f\"Book '{file_name}' downloaded and saved successfully in '{directory}'.\")\n",
    "    else:\n",
    "        print(f\"Failed to download the book. Status code: {response.status}\")\n",
    "\n",
    "\n",
    "# Define the directory to save the books\n",
    "directory = \"corpora\"\n",
    "\n",
    "def download_example_texts(download=False, directory=\"./corpora\"):\n",
    "    if download:\n",
    "        books = {\n",
    "            1661: \"the_adventures_of_sherlock_holmes.txt\",\n",
    "            1342: \"pride_and_prejudice.txt\", \n",
    "            174: \"the_picture_of_dorian_gray.txt\"\n",
    "        }\n",
    "        print(\"é–‹å§‹ä¸‹è¼‰ç¯„ä¾‹æ–‡æœ¬...\")\n",
    "\n",
    "        for book_id, file_name in books.items():\n",
    "            try:\n",
    "                download_text(book_id, file_name, directory)\n",
    "                print(f\"âœ… æˆåŠŸä¸‹è¼‰: {file_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ ä¸‹è¼‰å¤±æ•— {file_name}: {e}\")\n",
    "        \n",
    "        print(\"ç¯„ä¾‹æ–‡æœ¬ä¸‹è¼‰å®Œæˆï¼\")\n",
    "    else:\n",
    "        print(\"è·³éä¸‹è¼‰ç¯„ä¾‹æ–‡æœ¬ã€‚\")\n",
    "\n",
    "download_example_texts(download=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d1aade",
   "metadata": {},
   "source": [
    "## 4. Initialize the Evaluation Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b202f570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Backup file './chunking_evaluation/evaluation_framework/general_evaluation_data/generated_queries_and_excerpts_backup.csv' already exists.\n",
      "ğŸ“– Reading file paths from the backup file.\n",
      "\n",
      "âœ… The file paths to be processed have been saved in corpora_paths_list\n",
      "ğŸ“ The generated queries will be saved to: ./chunking_evaluation/evaluation_framework/general_evaluation_data/generated_queries_and_excerpts.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "\n",
    "# Define your corpus folder path\n",
    "corpora_directory = \"./chunking_evaluation/evaluation_framework/general_evaluation_data/corpora\"\n",
    "# Define the path to check\n",
    "queries_backup_path = \"./chunking_evaluation/evaluation_framework/general_evaluation_data/generated_queries_and_excerpts_backup.csv\"\n",
    "# Define the target output path\n",
    "queries_csv_path = \"./chunking_evaluation/evaluation_framework/general_evaluation_data/generated_queries_and_excerpts.csv\"\n",
    "\n",
    "# --- Core logic modification ---\n",
    "corpora_paths_list = []\n",
    "\n",
    "# Check if the backup file exists\n",
    "if os.path.exists(queries_backup_path):\n",
    "    print(f\"âœ… Backup file '{queries_backup_path}' already exists.\")\n",
    "    print(f\"ğŸ“– Reading file paths from the backup file.\")\n",
    "    \n",
    "    # Read the 'corpus_id' column from the CSV backup file\n",
    "    backup_df = pd.read_csv(queries_backup_path)\n",
    "    \n",
    "    # Standardize the paths and extract the unique list\n",
    "    corpora_paths_list = [os.path.normpath(path).replace('\\\\', '/') for path in backup_df['corpus_id'].unique()]\n",
    "else:\n",
    "    print(f\"ğŸš§ Backup file '{queries_backup_path}' not found, starting sampling.\")\n",
    "\n",
    "    analyzer = DatasetAnalyzer(corpora_directory)\n",
    "    analyzer.analyze_folder()\n",
    "    analyzer.generate_report()\n",
    "    sample = analyzer.get_stratified_sample(100)\n",
    "\n",
    "    # Extract the file path list and ensure it's in a standardized format\n",
    "    corpora_paths_list = [os.path.normpath(file_info['file_path']).replace('\\\\', '/') for file_info in sample]\n",
    "\n",
    "    print(f\"\\nğŸ¯ Stratified sampling complete, selected {len(sample)} files:\")\n",
    "    for i, file_info in enumerate(sample, 1):\n",
    "        print(f\"  {i:2d}. {file_info['category']} - {file_info['filename']}\")\n",
    "\n",
    "# --- Rest of the code remains the same ---\n",
    "print(f\"\\nâœ… The file paths to be processed have been saved in corpora_paths_list\")\n",
    "print(f\"ğŸ“ The generated queries will be saved to: {queries_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4131bb11",
   "metadata": {},
   "source": [
    "## 5. Generate Queries and Excerpts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179bc6ea",
   "metadata": {},
   "source": [
    "### 5.1 Memory manage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d054b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade ipywidgets --quiet\n",
    "%pip install accelerate --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3fb8e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨é ä¼°æ¨¡å‹åˆ†ä½ˆ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9fb56c384f14109a1c382e90e6fc7c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ ¹æ“š max_memory={0: '12GiB', 'cpu': '8GiB'} é ä¼°è£ç½®åˆ†ä½ˆä¸­...\n",
      "é ä¼°çš„è£ç½®åˆ†ä½ˆ: OrderedDict({'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 0, 'model.layers.15': 0, 'model.layers.16': 0, 'model.layers.17': 0, 'model.layers.18': 0, 'model.layers.19': 0, 'model.layers.20': 0, 'model.layers.21': 0, 'model.layers.22': 0, 'model.layers.23': 0, 'model.layers.24': 'cpu', 'model.layers.25': 'cpu', 'model.layers.26': 'cpu', 'model.layers.27': 'cpu', 'model.layers.28': 'cpu', 'model.layers.29': 'cpu', 'model.layers.30': 'cpu', 'model.layers.31': 'cpu', 'model.norm': 'cpu', 'model.rotary_emb': 'cpu', 'lm_head': 'cpu'})\n",
      "æ­£åœ¨è¼‰å…¥ meta-llama/Llama-3.1-8B-Instruct æ¨¡å‹...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f9c271c487343d5a72154893c266b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/Llama-3.1-8B-Instruct æ¨¡å‹å·²æˆåŠŸè¼‰å…¥åˆ°è£ç½®: {'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 0, 'model.layers.15': 0, 'model.layers.16': 0, 'model.layers.17': 0, 'model.layers.18': 0, 'model.layers.19': 0, 'model.layers.20': 0, 'model.layers.21': 0, 'model.layers.22': 0, 'model.layers.23': 0, 'model.layers.24': 'cpu', 'model.layers.25': 'cpu', 'model.layers.26': 'cpu', 'model.layers.27': 'cpu', 'model.layers.28': 'cpu', 'model.layers.29': 'cpu', 'model.layers.30': 'cpu', 'model.layers.31': 'cpu', 'model.norm': 'cpu', 'model.rotary_emb': 'cpu', 'lm_head': 'cpu'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the evaluation\n",
    "evaluation = SyntheticEvaluation(corpora_paths_list, queries_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc149eb",
   "metadata": {},
   "source": [
    "### 5.2 Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a19b652c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å‚™ä»½æª”æ¡ˆ './chunking_evaluation/evaluation_framework/general_evaluation_data/generated_queries_and_excerpts_backup.csv' å·²å­˜åœ¨ï¼Œè·³éæŸ¥è©¢ç”Ÿæˆæ­¥é©Ÿã€‚\n"
     ]
    }
   ],
   "source": [
    "# Generate queries and excerpts, and save to CSV\n",
    "if os.path.exists(queries_backup_path):\n",
    "    print(f\"âœ… å‚™ä»½æª”æ¡ˆ '{queries_backup_path}' å·²å­˜åœ¨ï¼Œè·³éæŸ¥è©¢ç”Ÿæˆæ­¥é©Ÿã€‚\")\n",
    "else:\n",
    "    print(f\"ğŸš€ æ­£åœ¨ç”ŸæˆæŸ¥è©¢èˆ‡æ‘˜éŒ„...\")\n",
    "    evaluation.generate_queries_and_excerpts(approximate_excerpts=True, num_rounds=1, queries_per_corpus=1)\n",
    "    print(f\"âœ”ï¸ æŸ¥è©¢ç”Ÿæˆå®Œæˆï¼Œå·²å„²å­˜è‡³ '{queries_csv_path}'\")\n",
    "#evaluation.debug_full_output(\"./corpora/113_2_è³‡è¨Šå·¥ç¨‹å­¸ç³»_å¾®ç©åˆ†(äºŒ)[159040]_é™³æ¦®éŠ˜.html\", use_approx=True, save_to_file=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0254ee6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ é–‹å§‹ä¿®å¾© CSV ä¸­çš„ references æ¬„ä½...\n",
      "ğŸ”§ å·²ä¿®æ­£ 'corpus_id' æ¬„ä½ä¸­çš„è·¯å¾‘æ ¼å¼ã€‚\n",
      "ğŸ“Š è®€å–åˆ° 181 æ¢è¨˜éŒ„\n",
      "æ­£åœ¨ä¿®å¾© references æ¬„ä½...\n",
      "âœ… ä¿®å¾©å®Œæˆ!\n",
      "   æˆåŠŸä¿®å¾©: 181 æ¢\n",
      "   ä¿®å¾©å¤±æ•—: 0 æ¢\n",
      "   ç¸½è¨ˆ: 181 æ¢\n",
      "ğŸ” é©—è­‰ CSV æ–‡ä»¶å®Œæ•´æ€§...\n",
      "âŒ é©—è­‰éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: cannot access local variable 'df' where it is not associated with a value\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation.repair_csv_references() \n",
    "evaluation.validate_csv_integrity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cc9303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply filter to remove queries with poor excerpts\n",
    "#evaluation.filter_poor_excerpts(threshold=0.36)\n",
    "\n",
    "# Apply filter to remove duplicates\n",
    "#evaluation.filter_duplicates(threshold=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e449e2",
   "metadata": {},
   "source": [
    "## 6. Run the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "599e6be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Failed to use the frozen embeddings originally used in the paper. As a result, this package will now generate a new set of embeddings. The change should be minimal and only come from the noise floor of SentenceTransformer's embedding function. The error:  Collection [auto_questions_bge_m3] does not exists\n",
      "Existing 'auto_questions' collection deleted.\n",
      "New 'auto_questions' collection created.\n",
      "181 questions added to 'auto_questions' collection.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "chroma_db_path = \"./chunking_evaluation/evaluation_framework/general_evaluation_data/questions_db\"\n",
    "\n",
    "# Initialize evaluation\n",
    "evaluation = GeneralEvaluation()\n",
    "\n",
    "results = []\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Display the DataFrame\n",
    "display_handle = display(df, display_id=True)\n",
    "\n",
    "for chunker in chunkers:\n",
    "    result = evaluation.run(chunker, get_bge_m3_embedding_function(), retrieve=5, db_to_save_chunks=chroma_db_path)\n",
    "    del result['corpora_scores']  \n",
    "    chunk_size = chunker._chunk_size if hasattr(chunker, '_chunk_size') else 0\n",
    "    chunk_overlap = chunker._chunk_overlap if hasattr(chunker, '_chunk_overlap') else 0\n",
    "    result['chunker'] = chunker.__class__.__name__ + f\"_{chunk_size}_{chunk_overlap}\"\n",
    "    results.append(result)\n",
    "\n",
    "    # Update the DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    clear_output(wait=True)\n",
    "    display_handle.update(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f09dc7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iou_mean</th>\n",
       "      <th>iou_std</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>precision_omega_mean</th>\n",
       "      <th>precision_omega_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>chunker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RecursiveTokenChunker_512_50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FixedTokenChunker_512_50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RecursiveTokenChunker_512_100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FixedTokenChunker_512_100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RecursiveTokenChunker_512_150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FixedTokenChunker_512_150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RecursiveTokenChunker_512_200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FixedTokenChunker_512_200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>str_0_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iou_mean  iou_std  recall_mean  recall_std  precision_omega_mean  \\\n",
       "0       0.0      0.0          0.0         0.0                   0.0   \n",
       "1       0.0      0.0          0.0         0.0                   0.0   \n",
       "2       0.0      0.0          0.0         0.0                   0.0   \n",
       "3       0.0      0.0          0.0         0.0                   0.0   \n",
       "4       0.0      0.0          0.0         0.0                   0.0   \n",
       "5       0.0      0.0          0.0         0.0                   0.0   \n",
       "6       0.0      0.0          0.0         0.0                   0.0   \n",
       "7       0.0      0.0          0.0         0.0                   0.0   \n",
       "8       0.0      0.0          0.0         0.0                   0.0   \n",
       "\n",
       "   precision_omega_std  precision_mean  precision_std  \\\n",
       "0                  0.0             0.0            0.0   \n",
       "1                  0.0             0.0            0.0   \n",
       "2                  0.0             0.0            0.0   \n",
       "3                  0.0             0.0            0.0   \n",
       "4                  0.0             0.0            0.0   \n",
       "5                  0.0             0.0            0.0   \n",
       "6                  0.0             0.0            0.0   \n",
       "7                  0.0             0.0            0.0   \n",
       "8                  0.0             0.0            0.0   \n",
       "\n",
       "                         chunker  \n",
       "0   RecursiveTokenChunker_512_50  \n",
       "1       FixedTokenChunker_512_50  \n",
       "2  RecursiveTokenChunker_512_100  \n",
       "3      FixedTokenChunker_512_100  \n",
       "4  RecursiveTokenChunker_512_150  \n",
       "5      FixedTokenChunker_512_150  \n",
       "6  RecursiveTokenChunker_512_200  \n",
       "7      FixedTokenChunker_512_200  \n",
       "8                        str_0_0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
